{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网格搜索（GridSearchCV）自动调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、手工枚举法，确定最佳参数组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 以支持向量机（SVM）分类模型调参为例\n",
    "+ 定义gamma和C两个参数的取值列表\n",
    "+ 定义循环，使用不同的参数组合创建模型并评估成绩\n",
    "+ 取最佳成绩的参数组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris \n",
    "\n",
    "iris = load_iris() # 加载数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0) \n",
    " \n",
    "best_score = 0 # 最佳成绩\n",
    "\n",
    "# 对每种参数组合都训练一个模型，评估其成绩，找到最佳参数组合\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:     \n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "        svm = SVC(gamma=gamma, C=C).fit(X_train, y_train) \n",
    "        score = svm.score(X_test, y_test) # 在测试集上评估SVC\n",
    "        # 如果得到了更高的分数，则保存该分数和对应的参数         \n",
    "        if score > best_score:             \n",
    "            best_score = score             \n",
    "            best_parameters = {'C': C, 'gamma': gamma} \n",
    " \n",
    "print(\"Best score: {:.2f}\".format(best_score))  # 输出最佳成绩\n",
    "print(\"Best parameters: {}\".format(best_parameters)) # 输出最佳参数组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、拆分出验证集进行调参（避免在测试集上调参）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 如果模型调参在测试集上进行，就不能保证测试的客观性（相当于练习题与考试题不分）\n",
    "+ 因此，调参时需要拆分出独立的验证集，在验证集上调参\n",
    "+ 测试集专门用于测试（即测试集不参与训练和调参过程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先，将数据拆分为（训练+验证集）与测试集 \n",
    "X_train_valid, X_test, y_train_valid, y_test = train_test_split(iris.data, iris.target, random_state=0) \n",
    "\n",
    "# 然后，将（训练+验证集）拆分为训练集与验证集 \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_valid, y_train_valid, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_set size: 84 , Validation_set size: 28 , Test_set size: 38\n",
      "Best score on validation_set: 0.96\n",
      "Best parameters:  {'C': 10, 'gamma': 0.001}\n",
      "Test_set score with best parameters: 0.92\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "\n",
    "# 对每种参数组合都训练一个模型，评估其成绩，找到最佳参数组合\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:     \n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "        svm = SVC(gamma=gamma, C=C).fit(X_train, y_train) \n",
    "        score = svm.score(X_valid, y_valid) # 注意！这里改为在验证集上评估模型    \n",
    "        if score > best_score:             \n",
    "            best_score = score             \n",
    "            best_parameters = {'C': C, 'gamma': gamma} \n",
    "\n",
    "print(\"Training_set size: {} , Validation_set size: {} , Test_set size: {}\"\n",
    "      .format(X_train.shape[0], X_valid.shape[0], X_test.shape[0])) \n",
    "\n",
    "# 利用调参得到的最佳参数组合，在(训练+验证集)上重新构建一个模型，并在测试集上进行评估 \n",
    "svm = SVC(**best_parameters) \n",
    "svm.fit(X_train_valid, y_train_valid) \n",
    "test_score = svm.score(X_test, y_test) # 测试集只用做最终评估，不参与调参，保证测试的客观性\n",
    "\n",
    "print(\"Best score on validation_set: {:.2f}\".format(best_score)) \n",
    "print(\"Best parameters: \", best_parameters) \n",
    "print(\"Test_set score with best parameters: {:.2f}\".format(test_score)) # 输出测试成绩\n",
    "#最终结果的好坏与初始数据的划分结果有很大关系，为了处理这种情况，可以采用交叉验证的方式来减少偶然性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、使用网格搜索（GridSearchCV）自动调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ GridSearchCV整合了自动调参和交叉验证功能\n",
    "+ .best_params_和.best_score_属性，分别代表最佳参数组合及最佳成绩\n",
    "+ 相对于手工枚举，网格搜素自动调参更高效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'gamma': 0.1}\n",
      "Best cross-validation score: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # 引入网格搜索类\n",
    "\n",
    "# 定义参数列表\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]} \n",
    "\n",
    "# 定义GridSearchCV对象，注意参数\n",
    "# 参数1-模型\n",
    "# 参数2-参数列表\n",
    "# 参数3-交叉验证次数（网格搜索具有交叉验证功能）\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=10)\n",
    "\n",
    "# 拆分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "grid_search.fit(X_train, y_train) # 将训练数据交给GridSearchCV对象\n",
    "\n",
    "# 输出最佳参数组合及最佳成绩（利用.best_params_和.best_score_属性）\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_)) \n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.交叉验证减少偶然性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score on validation set:0.96\n",
      "Best parameters:{'gamma': 0.01, 'C': 100}\n",
      "Score on testing set:0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "best_score = 0.0\n",
    "for gamma in [0.001,0.01,0.1,1,10,100]:\n",
    "    for C in [0.001,0.01,0.1,1,10,100]:\n",
    "        svm = SVC(gamma=gamma,C=C)\n",
    "        scores = cross_val_score(svm,X_train,y_train,cv=3) #3折交叉验证\n",
    "        score = scores.mean() #取平均数\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {\"gamma\":gamma,\"C\":C}\n",
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_train,y_train)\n",
    "test_score = svm.score(X_test,y_test)\n",
    "print(\"Best score on validation set:{:.2f}\".format(best_score))\n",
    "print(\"Best parameters:{}\".format(best_parameters))\n",
    "print(\"Score on testing set:{:.2f}\".format(test_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
